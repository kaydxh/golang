type: com.google.api.codegen.ConfigProto
config_schema_version: 2.0.0
language_settings:
  java:
    package_name: com.google.cloud.vision.v1
    release_level: GA
  python:
    package_name: google.cloud.vision_v1.gapic
  go:
    package_name: cloud.google.com/go/vision/apiv1
    release_level: GA
  csharp:
    package_name: Google.Cloud.Vision.V1
    release_level: GA
  ruby:
    package_name: Google::Cloud::Vision::V1
  php:
    package_name: Google\Cloud\Vision\V1
  nodejs:
    package_name: vision.v1
    domain_layer_location: google-cloud
interfaces:
- name: google.cloud.vision.v1.ImageAnnotator
  smoke_test:
    method: BatchAnnotateImages
    init_fields:
    - requests[0].image.source.gcs_image_uri="gs://cloud-samples-data/vision/face_detection/celebrity_recognition/sergey.jpg"
    - requests[0].features[0].type=FACE_DETECTION
  methods:
  - name: BatchAnnotateFiles
    samples:
      standalone:
      - region_tag: vision_batch_annotate_files_gcs
        value_sets: [vision_batch_annotate_files_gcs]
      - region_tag: vision_batch_annotate_files
        value_sets: [vision_batch_annotate_files]
    sample_value_sets:
    - id: vision_batch_annotate_files_gcs
      description: "Perform batch file annotation"
      parameters:
        defaults:
        - requests[0].input_config.gcs_source.uri=gs://cloud-samples-data/vision/document_understanding/kafka.pdf
        - requests[0].features[0].type=DOCUMENT_TEXT_DETECTION
        - requests[0].pages[0]=1
        - requests[0].pages[1]=2
        - requests[0].pages[2]="-1"
        attributes:
        - parameter: requests[0].input_config.gcs_source.uri
          sample_argument_name: storage_uri
          description: "Cloud Storage URI to source image in the format gs://[bucket]/[file]"
        - parameter: requests[0].pages[0]
          description: |
            The service can process up to 5 pages per document file.
            Here we specify the first, second, and last page of the document to be processed.
      on_success:
      - loop:
          collection: $resp.responses[0].responses
          variable: image_response
          body:
          - print: ["Full text: %s", image_response.full_text_annotation.text]
          - loop:
              collection: image_response.full_text_annotation.pages
              variable: page
              body:
              - loop:
                  collection: page.blocks
                  variable: block
                  body:
                  - print: ["\nBlock confidence: %s", block.confidence]
                  - loop:
                      collection: block.paragraphs
                      variable: par
                      body:
                      - print: ["\tParagraph confidence: %s", par.confidence]
                      - loop:
                          collection: par.words
                          variable: word
                          body:
                          - print: ["\t\tWord confidence: %s", word.confidence]
                          - loop:
                              collection: word.symbols
                              variable: symbol
                              body:
                              - print: ["\t\t\tSymbol: %s, (confidence: %s)", symbol.text, symbol.confidence]
    - id: vision_batch_annotate_files
      description: "Perform batch file annotation"
      parameters:
        defaults:
        - requests[0].input_config.mime_type="application/pdf"
        - requests[0].input_config.content="resources/kafka.pdf"
        - requests[0].features[0].type=DOCUMENT_TEXT_DETECTION
        - requests[0].pages[0]=1
        - requests[0].pages[1]=2
        - requests[0].pages[2]="-1"
        attributes:
        - parameter: requests[0].input_config.mime_type
          description: "Supported mime_type: application/pdf, image/tiff, image/gif"
        - parameter: requests[0].input_config.content
          sample_argument_name: file_path
          read_file: true
          description: Path to local pdf file, e.g. /path/document.pdf
        - parameter: requests[0].pages[0]
          description: "The service can process up to 5 pages per document file. Here we specify the first, second, and last page of the document to be processed."
      on_success:
      - loop:
          collection: $resp.responses[0].responses
          variable: image_response
          body:
          - print: ["Full text: %s", image_response.full_text_annotation.text]
          - loop:
              collection: image_response.full_text_annotation.pages
              variable: page
              body:
              - loop:
                  collection: page.blocks
                  variable: block
                  body:
                  - print: ["\nBlock confidence: %s", block.confidence]
                  - loop:
                      collection: block.paragraphs
                      variable: par
                      body:
                      - print: ["\tParagraph confidence: %s", par.confidence]
                      - loop:
                          collection: par.words
                          variable: word
                          body:
                          - print: ["\t\tWord confidence: %s", word.confidence]
                          - loop:
                              collection: word.symbols
                              variable: symbol
                              body:
                              - print: ["\t\t\tSymbol: %s, (confidence: %s)", symbol.text, symbol.confidence]
  - name: AsyncBatchAnnotateImages
    long_running:
      initial_poll_delay_millis: 20000
      poll_delay_multiplier: 1.5
      max_poll_delay_millis: 45000
      total_poll_timeout_millis: 86400000
    samples:
      standalone:
      - region_tag: vision_async_batch_annotate_images
        value_sets: [vision_async_batch_annotate_images]
    sample_value_sets:
    - id: vision_async_batch_annotate_images
      title: Async Batch Image Annotation
      description: "Perform async batch image annotation"
      parameters:
        defaults:
        - requests[0].image.source.image_uri=gs://cloud-samples-data/vision/label/wakeupcat.jpg
        - requests[0].features[0].type=LABEL_DETECTION
        - requests[0].features[1].type=IMAGE_PROPERTIES
        - output_config.gcs_destination.uri=gs://your-bucket/prefix/
        - output_config.batch_size=2
        attributes:
        - parameter: requests[0].image.source.image_uri
          sample_argument_name: input_image_uri
        - parameter: output_config.gcs_destination.uri
          sample_argument_name: output_uri
        - parameter: output_config.batch_size
          description: The max number of responses to output in each JSON file
      on_success:
      - comment: ["The output is written to GCS with the provided output_uri as prefix"]
      - define: gcs_output_uri=$resp.output_config.gcs_destination.uri
      - print: ["Output written to GCS with prefix: %s", gcs_output_uri]
  - name: AsyncBatchAnnotateFiles
    long_running:
      initial_poll_delay_millis: 20000
      poll_delay_multiplier: 1.5
      max_poll_delay_millis: 45000
      total_poll_timeout_millis: 86400000
- name: google.cloud.vision.v1.ProductSearch
  methods:
  - name: ImportProductSets
    long_running:
      initial_poll_delay_millis: 20000
      poll_delay_multiplier: 1.5
      max_poll_delay_millis: 45000
      total_poll_timeout_millis: 86400000
  - name: PurgeProducts
    long_running:
      initial_poll_delay_millis: 20000
      poll_delay_multiplier: 1.5
      max_poll_delay_millis: 45000
      total_poll_timeout_millis: 86400000
# Force string formatting functions to be generated.
enable_string_format_functions_override: true
